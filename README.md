This project explores ensemble methods in machine learning using real-world and toy datasets. It includes the implementation and evaluation of multiple classifiers, voting ensembles, and custom-built random forests. The key components are:

- Training and evaluating multiple classifiers on the Cover Type dataset
- Creating hard and soft voting ensembles and analyzing their effectiveness
- Building a tuned decision tree model using GridSearchCV
- Constructing a custom random forest using 1,200 individual decision trees trained on bootstrapped subsets
- Analyzing ensemble performance vs. individual models

This project demonstrates how ensemble learning can improve prediction accuracy and model robustness through aggregation.
